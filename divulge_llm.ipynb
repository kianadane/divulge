{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPA Water Quality Data for CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sodapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msodapy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Socrata\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, pipeline\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sodapy'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from sodapy import Socrata\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import langchain\n",
    "from langchain.agents import initialize_agent, Tool, AgentType, AgentExecutor\n",
    "from langchain.llms import OpenAI, OpenAIChat, HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory, ConversationSummaryBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use a known-valid site in California (e.g., USGS-11447650)\n",
    "BASE_URL = \"https://www.waterqualitydata.us/data/Result/search\"\n",
    "params = {\n",
    "    \"siteid\": \"USGS-11447650\",\n",
    "    \"mimeType\": \"csv\",\n",
    "    \"zip\": \"no\"\n",
    "}\n",
    "\n",
    "response = requests.get(BASE_URL, params=params)\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(response.text[:500])  # Check for content\n",
    "\n",
    "# Load into DataFrame if there's content\n",
    "if response.text.strip():  # Make sure it's not empty\n",
    "    df = pd.read_csv(StringIO(response.text))\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"⚠️ No data returned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of stations in CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "OrganizationIdentifier,OrganizationFormalName,MonitoringLocationIdentifier,MonitoringLocationName,MonitoringLocationTypeName,MonitoringLocationDescriptionText,HUCEightDigitCode,DrainageAreaMeasure/MeasureValue,DrainageAreaMeasure/MeasureUnitCode,ContributingDrainageAreaMeasure/MeasureValue,ContributingDrainageAreaMeasure/MeasureUnitCode,LatitudeMeasure,LongitudeMeasure,SourceMapScaleNumeric,HorizontalAccuracyMeasure/MeasureValue,HorizontalAccuracyMeasure/MeasureUnitCode,HorizontalCollectionMethodName,HorizontalCoordinateReferenceSystemDatumName,VerticalMeasure/MeasureValue,VerticalMeasure/MeasureUnitCode,VerticalAccuracyMeasure/MeasureValue,VerticalAccuracyMeasure/MeasureUnitCode,VerticalCollectionMethodName,VerticalCoordinateReferenceSystemDatumName,CountryCode,StateCode,CountyCode,AquiferName,LocalAqfrName,FormationTypeText,AquiferTypeName,ConstructionDateText,WellDepthMeasure/MeasureValue,WellDepthMeasure/MeasureUnitCode,WellHoleDepthMeasure/MeasureValue,WellHoleDepthMeasure/Measure\n"
     ]
    }
   ],
   "source": [
    "STATION_URL = \"https://www.waterqualitydata.us/data/Station/search\"\n",
    "\n",
    "params = {\n",
    "    \"statecode\": \"US:06\",   # California\n",
    "    \"mimeType\": \"csv\",\n",
    "    \"zip\": \"no\"\n",
    "}\n",
    "\n",
    "response = requests.get(STATION_URL, params=params)\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "OrganizationIdentifier,OrganizationFormalName,ActivityIdentifier,ActivityTypeCode,ActivityMediaName,ActivityMediaSubdivisionName,ActivityStartDate,ActivityStartTime/Time,ActivityStartTime/TimeZoneCode,ActivityEndDate,ActivityEndTime/Time,ActivityEndTime/TimeZoneCode,ActivityDepthHeightMeasure/MeasureValue,ActivityDepthHeightMeasure/MeasureUnitCode,ActivityDepthAltitudeReferencePointText,ActivityTopDepthHeightMeasure/MeasureValue,ActivityTopDepthHeightMeasure/MeasureUnitCode,ActivityBottomDepthHeightMeasure/MeasureValue,ActivityBottomDepthHeightMeasure/MeasureUnitCode,ProjectIdentifier,ActivityConductingOrganizationText,MonitoringLocationIdentifier,ActivityCommentText,SampleAquifer,HydrologicCondition,HydrologicEvent,SampleCollectionMethod/MethodIdentifier,SampleCollectionMethod/MethodIdentifierContext,SampleCollectionMethod/MethodName,SampleCollectionEquipmentName,ResultDetectionConditionText,CharacteristicName,ResultSampleFractionText,ResultMeasureValue,ResultMeasure/MeasureUnitCode,M\n"
     ]
    }
   ],
   "source": [
    "RESULT_URL = \"https://www.waterqualitydata.us/data/Result/search\"\n",
    "\n",
    "params = {\n",
    "    \"siteid\": \"USGS-11447650\",   # A known valid station ID from California\n",
    "    \"mimeType\": \"csv\",\n",
    "    \"zip\": \"no\"\n",
    "}\n",
    "\n",
    "response = requests.get(RESULT_URL, params=params)\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SF Excavation Permits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['permit_number', 'streetname', 'cross_street_1', 'cross_street_2', 'utility_contractor', 'permit_reason', 'utility_type', 'effective_date', 'expiration_date', 'status', 'cnn']\n"
     ]
    }
   ],
   "source": [
    "# Initialize Socrata client for San Francisco's open data portal\n",
    "client = Socrata(\"data.sfgov.org\", None)\n",
    "\n",
    "# Dataset ID for Utility Excavation Permits\n",
    "dataset_id = \"smdf-6c45\"\n",
    "\n",
    "# Fetch the latest 1000 records\n",
    "results = client.get(dataset_id, limit=1000)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_records(results)\n",
    "\n",
    "# Display relevant fields\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sensor data\n",
    "df_results[\"ActivityStartDate\"] = pd.to_datetime(df_results[\"ActivityStartDate\"])\n",
    "\n",
    "# For permit data\n",
    "df_permits[\"effective_date\"] = pd.to_datetime(df_permits[\"effective_date\"], errors='coerce')\n",
    "df_permits[\"expiration_date\"] = pd.to_datetime(df_permits[\"expiration_date\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer loop to find relevant permits per sensor reading\n",
    "def find_matching_permits(sensor_row, permits_df):\n",
    "    matches = permits_df[\n",
    "        (permits_df[\"effective_date\"] <= sensor_row[\"ActivityStartDate\"]) &\n",
    "        (permits_df[\"expiration_date\"] >= sensor_row[\"ActivityStartDate\"])\n",
    "    ]\n",
    "    return matches\n",
    "\n",
    "# Apply logic\n",
    "sensor_with_permits = []\n",
    "for _, row in df_results.iterrows():\n",
    "    matching_permits = find_matching_permits(row, df_permits)\n",
    "    for _, permit in matching_permits.iterrows():\n",
    "        sensor_with_permits.append({\n",
    "            \"timestamp\": row[\"ActivityStartDate\"],\n",
    "            \"characteristic\": row[\"CharacteristicName\"],\n",
    "            \"value\": row[\"ResultMeasureValue\"],\n",
    "            \"unit\": row[\"ResultMeasure/MeasureUnitCode\"],\n",
    "            \"permit_number\": permit[\"permit_number\"],\n",
    "            \"permit_reason\": permit[\"permit_reason\"],\n",
    "            \"street\": permit[\"streetname\"],\n",
    "            \"contractor\": permit[\"utility_contractor\"]\n",
    "        })\n",
    "\n",
    "# Create joined DataFrame\n",
    "df_joined = pd.DataFrame(sensor_with_permits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_permits_by_date(target_date, permits_df, window_days=3):\n",
    "    # Look +/- window_days around the event\n",
    "    start = target_date - timedelta(days=window_days)\n",
    "    end = target_date + timedelta(days=window_days)\n",
    "    \n",
    "    matches = permits_df[\n",
    "        (permits_df[\"effective_date\"] <= end) & (permits_df[\"expiration_date\"] >= start)\n",
    "    ]\n",
    "    return matches.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sensor_anomalies(characteristic_name, df_sensor, z_threshold=2.0):\n",
    "    \"\"\"\n",
    "    Find anomalies in the sensor dataset based on a simple z-score method.\n",
    "    \n",
    "    Args:\n",
    "        characteristic_name (str): e.g., 'Dissolved oxygen (DO)', 'Water temperature'\n",
    "        df_sensor (DataFrame): Sensor data with columns: 'CharacteristicName', 'ResultMeasureValue', 'ActivityStartDate'\n",
    "        z_threshold (float): How many standard deviations from mean counts as anomaly (default = 2.0)\n",
    "\n",
    "    Returns:\n",
    "        list of dicts: Anomalous records\n",
    "    \"\"\"\n",
    "    # Filter by characteristic\n",
    "    df_filtered = df_sensor[df_sensor[\"CharacteristicName\"].str.contains(characteristic_name, case=False, na=False)].copy()\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        return [{\"message\": f\"No data found for characteristic: {characteristic_name}\"}]\n",
    "\n",
    "    # Convert result to numeric, handle missing values\n",
    "    df_filtered[\"ResultMeasureValue\"] = pd.to_numeric(df_filtered[\"ResultMeasureValue\"], errors=\"coerce\")\n",
    "    df_filtered = df_filtered.dropna(subset=[\"ResultMeasureValue\"])\n",
    "\n",
    "    # Calculate mean and std\n",
    "    mean = df_filtered[\"ResultMeasureValue\"].mean()\n",
    "    std = df_filtered[\"ResultMeasureValue\"].std()\n",
    "\n",
    "    # Define upper and lower bounds\n",
    "    upper = mean + z_threshold * std\n",
    "    lower = mean - z_threshold * std\n",
    "\n",
    "    # Find anomalies\n",
    "    anomalies = df_filtered[(df_filtered[\"ResultMeasureValue\"] > upper) | (df_filtered[\"ResultMeasureValue\"] < lower)]\n",
    "\n",
    "    # Return a list of anomaly records\n",
    "    return anomalies[[\n",
    "        \"ActivityStartDate\", \n",
    "        \"CharacteristicName\", \n",
    "        \"ResultMeasureValue\", \n",
    "        \"ResultMeasure/MeasureUnitCode\"\n",
    "    ]].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"SearchPermitsByDate\",\n",
    "        func=lambda date: search_permits_by_date(pd.to_datetime(date), df_permits),\n",
    "        description=\"Useful for finding permits active near a specific date\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"SearchSensorAnomalies\",\n",
    "        func=lambda characteristic: search_sensor_anomalies(characteristic, df_results),\n",
    "        description=\"Useful for finding anomalies (like low oxygen or pressure events)\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize agent\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",  # Standard \"think-act-observe\" loop\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example prompt\n",
    "query = \"Were there any underground permits active when the oxygen levels dropped near USGS-11447650 last year?\"\n",
    "agent.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your HuggingFace token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your_huggingface_token_here\"\n",
    "\n",
    "# Load model directly from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "pipe(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your tools (same as before)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"SearchPermitsByDate\",\n",
    "        func=lambda date: search_permits_by_date(pd.to_datetime(date), df_permits),\n",
    "        description=\"Useful for finding permits active near a specific date\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"SearchSensorAnomalies\",\n",
    "        func=lambda characteristic: search_sensor_anomalies(characteristic, df_results),\n",
    "        description=\"Useful for finding anomalies (like low oxygen or pressure events)\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",  # Core reasoning agent\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Now run it!\n",
    "query = \"Were there any sewer repair permits near the oxygen drop at USGS-11447650 last March?\"\n",
    "agent.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
